{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)  # 0 = empty, 1 = X, -1 = O\n",
    "        self.current_player = random.choice([1,-1]) \n",
    "\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player *= -1\n",
    "\n",
    "    def make_move(self, row, col):\n",
    "        if self.board[row, col] == 0:\n",
    "            self.board[row, col] = self.current_player\n",
    "            self.current_player *= -1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_winner(self, player):\n",
    "        # check rows, cols and diags\n",
    "        for i in range(3):\n",
    "            if np.all(self.board[i, :] == player) or np.all(self.board[:, i] == player):\n",
    "                return True\n",
    "        if np.all(np.diag(self.board) == player) or np.all(np.diag(np.fliplr(self.board)) == player):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_draw(self):\n",
    "        return np.all(self.board != 0)\n",
    "\n",
    "    def get_available_moves(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def print_board(self):\n",
    "        symbols = {0: '⬜️', 1: '❌', -1: '🟢'}\n",
    "        for row in self.board:\n",
    "            print(' '.join([symbols[cell] for cell in row]))\n",
    "        print()\n",
    "\n",
    "    def print_result(self, player1, player2):\n",
    "        if self.is_winner(player1.symbol):\n",
    "            print(\"❌ has won!\")\n",
    "        elif self.is_winner(player2.symbol):\n",
    "            print(\"🟢 has won!\")\n",
    "        elif self.is_draw():\n",
    "            print(\"Draw!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer:\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol  # 1 per X, -1 per O\n",
    "\n",
    "    def choose_move(self, game):\n",
    "        available_moves = game.get_available_moves()\n",
    "        if available_moves: \n",
    "            return random.choice(available_moves) \n",
    "        else:\n",
    "            return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningPlayer:\n",
    "    def __init__(self, symbol, alpha=0.1, gamma=0.9, epsilon=0.2):\n",
    "        self.symbol = symbol  # 1 per X, -1 per O\n",
    "        self.alpha = alpha    # learning rate\n",
    "        self.gamma = gamma    # discount factor\n",
    "        self.epsilon = epsilon  # exploring prob (epsilon greedy) \n",
    "        self.q_table = {}  # state -> action -> value\n",
    "\n",
    "    def get_state(self, game):\n",
    "        return str(game.board.reshape(9))\n",
    "\n",
    "    def choose_move(self, game):\n",
    "        state = self.get_state(game)\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            # exploring\n",
    "            return random.choice(game.get_available_moves())\n",
    "        else:\n",
    "            # exploiting\n",
    "            self.q_table.setdefault(state, {})\n",
    "            if not self.q_table[state]:\n",
    "                # if none -> rand\n",
    "                return random.choice(game.get_available_moves())\n",
    "            best_move = max(self.q_table[state], key=self.q_table[state].get)\n",
    "            return eval(best_move)\n",
    "\n",
    "    def update_q_values(self, prev_state, action, reward, next_state):\n",
    "        self.q_table.setdefault(prev_state, {})\n",
    "        self.q_table.setdefault(next_state, {})\n",
    "        prev_q = self.q_table[prev_state].get(str(action), 0)\n",
    "        max_next_q = max(self.q_table[next_state].values(), default=0)\n",
    "        self.q_table[prev_state][str(action)] = prev_q + self.alpha * (reward + self.gamma * max_next_q - prev_q)\n",
    "\n",
    "    def update_q_table(self, game_history):\n",
    "        # game_history = list (state, action, reward, next_state)\n",
    "        for i in range(len(game_history) - 1):\n",
    "            state, action, reward, next_state = game_history[i]\n",
    "            self.update_q_values(state, action, reward, next_state)\n",
    "\n",
    "        # update q-values for final_state\n",
    "        final_state, final_action, final_reward, _ = game_history[-1]\n",
    "        self.update_q_values(final_state, final_action, final_reward, final_state)\n",
    "\n",
    "    def receive_reward(self, game):\n",
    "        # rewars values\n",
    "        if game.is_winner(self.symbol):\n",
    "            return 1  # win\n",
    "        elif game.is_draw():\n",
    "            return 0  # draw, maybe -0.5\n",
    "        else:\n",
    "            return -1  # loss\n",
    "\n",
    "    def save_q_table(self, filename='q_table.pkl'):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.q_table, f)\n",
    "        print(f\"Q-table saved in {filename}.\")\n",
    "\n",
    "    def load_q_table(self, filename='q_table.pkl'):\n",
    "        with open(filename, 'rb') as f:\n",
    "            self.q_table = pickle.load(f)\n",
    "        print(f\"Q-table loaded from {filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(q_player, random_player, episodes=100000):\n",
    "    for episode in range(episodes):\n",
    "        game = TicTacToe()\n",
    "        game_history = []  # init game history\n",
    "\n",
    "        while True:\n",
    "            current_player = q_player if game.current_player == q_player.symbol else random_player\n",
    "            move = current_player.choose_move(game)\n",
    "            if move is None:  # if none break loop\n",
    "                break\n",
    "\n",
    "            # save current_state if qlplayer \n",
    "            if isinstance(current_player, QLearningPlayer):\n",
    "                prev_state = current_player.get_state(game)\n",
    "            \n",
    "            game.make_move(*move)\n",
    "\n",
    "            if isinstance(current_player, QLearningPlayer):\n",
    "                next_state = current_player.get_state(game)\n",
    "                reward = 0 \n",
    "                game_history.append((prev_state, move, reward, next_state))\n",
    "\n",
    "            # winner check\n",
    "            if game.is_winner(q_player.symbol) or game.is_winner(random_player.symbol) or game.is_draw():\n",
    "                final_reward = q_player.receive_reward(game)  # final reward\n",
    "                \n",
    "                # update reward for qlplayer\n",
    "                if isinstance(current_player, QLearningPlayer) and game_history:\n",
    "                    prev_state, move, _, next_state = game_history[-1]\n",
    "                    game_history[-1] = (prev_state, move, final_reward, next_state)\n",
    "                break\n",
    "\n",
    "        # update qtable with complete history\n",
    "        if game_history:\n",
    "            q_player.update_q_table(game_history)\n",
    "\n",
    "        game.reset()  # next game\n",
    "\n",
    "    print(\"Learning completed after {} episodes\".format(episodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning completed after 100000 episodes\n",
      "Q-table salvata in q_table_final.pkl.\n"
     ]
    }
   ],
   "source": [
    "player1 = QLearningPlayer(symbol=1)\n",
    "player2 = RandomPlayer(symbol=-1)\n",
    "#player1.load_q_table('q_table_final.pkl')\n",
    "play_game(player1, player2)\n",
    "player1.save_q_table('q_table_final.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table caricata da q_table_final.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing win rate: 100%|██████████| 1000/1000 [00:01<00:00, 756.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win rate: 77.60%\n",
      "Total games: 1000, Wins: 776, Losses: 165, Draws: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_win_rate(q_player, random_player, episodes=1000):\n",
    "    q_player.epsilon = 0  # no exploration\n",
    "    results = {\"wins\": 0, \"losses\": 0, \"draws\": 0}\n",
    "    q_player.load_q_table('q_table_final.pkl')\n",
    "\n",
    "    for _ in tqdm(range(episodes), desc=\"Testing win rate\"):\n",
    "        game = TicTacToe()\n",
    "        while True:\n",
    "            current_player = q_player if game.current_player == q_player.symbol else random_player\n",
    "            move = current_player.choose_move(game)\n",
    "            game.make_move(*move)\n",
    "            \n",
    "            if game.is_winner(q_player.symbol):\n",
    "                results[\"wins\"] += 1\n",
    "                break\n",
    "            elif game.is_winner(random_player.symbol):\n",
    "                results[\"losses\"] += 1\n",
    "                break\n",
    "            elif game.is_draw():\n",
    "                results[\"draws\"] += 1\n",
    "                break\n",
    "\n",
    "        game.reset()\n",
    "\n",
    "    win_rate = results[\"wins\"] / episodes\n",
    "    print(f\"Win rate: {win_rate*100:.2f}%\")\n",
    "    print(f\"Total games: {episodes}, Wins: {results['wins']}, Losses: {results['losses']}, Draws: {results['draws']}\")\n",
    "\n",
    "test_win_rate(player1, player2, episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Match Mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table caricata da q_table_final.pkl.\n",
      "🟢 🟢 ❌\n",
      "🟢 🟢 ❌\n",
      "❌ ❌ ❌\n",
      "\n",
      "Il giocatore ❌ ha vinto!\n"
     ]
    }
   ],
   "source": [
    "# single game\n",
    "game = TicTacToe()\n",
    "player1 = QLearningPlayer(symbol=1)  # X\n",
    "player2 = RandomPlayer(symbol=-1)  # O\n",
    "player1.load_q_table('q_table_final.pkl')\n",
    "\n",
    "while not game.is_draw() and not game.is_winner(player1.symbol) and not game.is_winner(player2.symbol):\n",
    "    if game.current_player == player1.symbol:\n",
    "        move = player1.choose_move(game)\n",
    "    else:\n",
    "        move = player2.choose_move(game)\n",
    "    \n",
    "    if move:\n",
    "        game.make_move(*move)\n",
    "    else:\n",
    "        break \n",
    "game.print_board()\n",
    "game.print_result(player1, player2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Me_vs_opponent(game, opponent):\n",
    "    if isinstance(opponent, QLearningPlayer):\n",
    "        opponent.epsilon = 0\n",
    "    \n",
    "    current_player = opponent if random.choice([True, False]) else \"Me\"\n",
    "    \n",
    "    print(f\"{current_player} starts the game.\")\n",
    "    \n",
    "    while True:\n",
    "        game.print_board()\n",
    "        \n",
    "        if current_player == \"Me\":\n",
    "            move = None\n",
    "            while move is None:\n",
    "                try:\n",
    "                    Me_move = int(input(\"Choose your move (1-9): \")) - 1\n",
    "                    row, col = divmod(Me_move, 3)\n",
    "                    if game.make_move(row, col):\n",
    "                        move = (row, col)\n",
    "                    else:\n",
    "                        print(\"Invalid move, please try again.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a number between 1 and 9.\")\n",
    "                    \n",
    "            if game.is_winner(-1):  # assuming Me is 🟢 (-1)\n",
    "                print(\"I'm the best.\")\n",
    "                break\n",
    "            current_player = opponent\n",
    "        else:\n",
    "            print(\"Let me think... 🤔\")\n",
    "            row, col = opponent.choose_move(game)\n",
    "            game.make_move(row, col)\n",
    "            print(f\"Opponent chose move {row * 3 + col + 1}\")\n",
    "            \n",
    "            if game.is_winner(1):  # assuming QLearningPlayer is ❌ (1)\n",
    "                print(\"Opponent wins.\")\n",
    "                break\n",
    "            current_player = \"Me\"\n",
    "        \n",
    "        if game.is_draw():\n",
    "            print(\"Draw!\")\n",
    "            break\n",
    "    \n",
    "    game.print_board()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table caricata da q_table_final.pkl.\n",
      "Me starts the game.\n",
      "⬜️ ⬜️ ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "\n",
      "⬜️ 🟢 ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "\n",
      "QLearningPlayer is thinking...\n",
      "QLearningPlayer chose move 5\n",
      "⬜️ 🟢 ⬜️\n",
      "⬜️ ❌ ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "\n",
      "⬜️ 🟢 🟢\n",
      "⬜️ ❌ ⬜️\n",
      "⬜️ ⬜️ ⬜️\n",
      "\n",
      "QLearningPlayer is thinking...\n",
      "QLearningPlayer chose move 9\n",
      "⬜️ 🟢 🟢\n",
      "⬜️ ❌ ⬜️\n",
      "⬜️ ⬜️ ❌\n",
      "\n",
      "Congratulations! You've won.\n",
      "🟢 🟢 🟢\n",
      "⬜️ ❌ ⬜️\n",
      "⬜️ ⬜️ ❌\n",
      "\n"
     ]
    }
   ],
   "source": [
    "game = TicTacToe()\n",
    "opponent = QLearningPlayer(symbol=1)\n",
    "opponent.load_q_table('q_table_final.pkl')\n",
    "\n",
    "Me_vs_opponent(game, opponent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
